{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1m2RpTeiCNQq"
   },
   "source": [
    "# Load Paper List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6G-XWU8JCNQr"
   },
   "outputs": [],
   "source": [
    "def read_papers(path):\n",
    "    papers = [[]]\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                papers[-1].append(line)\n",
    "            else:\n",
    "                papers.append([])\n",
    "    for p in papers:\n",
    "        assert len(p) == 2\n",
    "    return papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "m_5mqAPzCNQu",
    "outputId": "1af6fe5f-b149-452c-f2fd-d57bf41f400d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2kenize: Tying Subword Sequences for Chinese Script Conversion',\n",
       "  'Pranav A and Isabelle Augenstein'],\n",
       " ['A Batch Normalized Inference Network Keeps the KL Vanishing Away',\n",
       "  'Qile Zhu, Wei Bi, Xiaojiang Liu, Xiyao Ma, Xiaolin Li and Dapeng Wu'],\n",
       " ['A Call for More Rigor in Unsupervised Cross-lingual Learning',\n",
       "  'Mikel Artetxe, Sebastian Ruder, Dani Yogatama, Gorka Labaka and Eneko Agirre']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_papers = read_papers(\"./data/long.txt\")\n",
    "long_papers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AxPZti17CNQx",
    "outputId": "9b6ff125-9a55-4ce1-be39-aecaef1da8f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "SqL_0bNPCNQ0",
    "outputId": "5ea50937-8954-4de5-e22b-54f15bb61023"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A Complete Shift-Reduce Chinese Discourse Parser with Robust Dynamic Oracle',\n",
       "  'Shyh-Shiun Hung, Hen-Hsen Huang and Hsin-Hsi Chen'],\n",
       " ['A Diverse Corpus for Evaluating and Developing English Math Word Problem Solvers',\n",
       "  'Shen-yun Miao, Chao-Chun Liang and Keh-Yih Su'],\n",
       " ['A Frame-based Sentence Representation for Machine Reading Comprehension',\n",
       "  'Shaoru Guo, Ru Li, Hongye Tan, Xiaoli Li, Yong Guan, Hongyan Zhao and Yueping Zhang']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_papers = read_papers(\"./data/short.txt\")\n",
    "short_papers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rLNXH4MJCNQ2",
    "outputId": "0453196c-9c99-4b13-fdf1-21eb63abd839"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "TrBRORv3CNQ5",
    "outputId": "e3932d0d-a826-4117-8ae4-6259c9805f8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ADVISER: A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents',\n",
       "  'Chia-Yu Li, Daniel Ortega, Dirk Väth, Florian Lux, Lindsey Vanderlyn, Maximilian Schmidt, Michael Neumann, Moritz Völkel, Pavel Denisov, Sabrina Jenne, Zorica Kacarevic and Ngoc Thang Vu'],\n",
       " ['BENTO: A Visual Platform for Building Clinical NLP Pipelines Based on CodaLab',\n",
       "  'Yonghao Jin, Fei Li and Hong Yu'],\n",
       " ['Clinical-Coder: Assigning Interpretable ICD-10 Codes to Chinese Clinical Notes',\n",
       "  'Pengfei Cao, Chenwei Yan, xiangling fu, Yubo Chen, Kang Liu, Jun Zhao, Shengping Liu and Weifeng Chong']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_papers = read_papers(\"./data/demo.txt\")\n",
    "demo_papers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GySLkygHCNQ7",
    "outputId": "96ef1894-8ea7-44ba-f922-059a87cef4a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(demo_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "0cNcBqCsCNQ-",
    "outputId": "cb69362a-7bc3-4567-be1a-b21186930ca8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#NotAWhore! A Computational Linguistic Perspective of Rape Culture and Victimization on Social Media',\n",
       "  'Ashima Suvarna and Grusha Bhalla'],\n",
       " ['A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples',\n",
       "  'Zhao Meng and Roger Wattenhofer'],\n",
       " ['A Simple and Effective Dependency parser for Telugu',\n",
       "  'Sneha Nallani, Manish Shrivastava and Dipti Sharma']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_papers = read_papers(\"./data/student.txt\")\n",
    "student_papers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o9Zc2x0qCNRA",
    "outputId": "120a6c6f-7bf7-42cb-91d2-64eff8df937f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(student_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TUjlRSPtCNRD"
   },
   "source": [
    "# Search arXiv Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws04-fbRCNRD"
   },
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def search_arxiv_link(title):\n",
    "    link = None\n",
    "    for j in search(title, tld=\"co.in\", num=10, stop=1, pause=1.0, user_agent=\"acl2020\"):\n",
    "        if 'arxiv.org/abs' in j:\n",
    "            thepage = urllib.request.urlopen(j)\n",
    "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
    "            if similarity(title, searched_title) > 0.8:\n",
    "                link = j\n",
    "                break\n",
    "            else:\n",
    "                print(\"NOT MATCHED\")\n",
    "                print(title)\n",
    "                print(searched_title)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAJu9189CNRF"
   },
   "outputs": [],
   "source": [
    "def generate_paper_list_with_arxiv_link(f, papers):\n",
    "    for p in tqdm(papers):\n",
    "        title, authors = p\n",
    "        link = search_arxiv_link(title.lower())\n",
    "        if link:\n",
    "            f.write(f\"- {title} [[arXiv]]({link})\\n\")\n",
    "        else:\n",
    "            f.write(f\"- {title}\\n\")\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gk2bFBdqCNRI",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/571 [00:32<32:10,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "a generative model for joint natural language understanding and generation\n",
      "semi-supervised neural text generation by joint learning of natural language generation and natural language understanding models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 31/571 [01:56<31:59,  3.56s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "adaptive compression of word embeddings\n",
      "online embedding compression for text classification using low rank matrix factorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 32/571 [02:00<32:14,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "addressing posterior collapse with mutual information for improved variational neural machine translation\n",
      "improved variational neural machine translation by promoting mutual information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 53/571 [03:03<27:08,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "attentive pooling with learnable norms for text representation\n",
      "attentive pooling networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 68/571 [03:55<29:14,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "bilingual dictionary based neural machine translation without using parallel sentences\n",
      "bridging neural machine translation and bilingual dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 73/571 [04:12<28:17,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "boosting neural machine translation with similar translations\n",
      "neural machine translation from simplified translations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 96/571 [05:25<25:46,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "contextualized weak supervision for text classification\n",
      "weakly-supervised neural text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 103/571 [05:47<26:54,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "cross-lingual unsupervised sentiment classification with multi-view transfer learning\n",
      "multi-source cross-lingual model transfer: learning what to share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 109/571 [06:10<29:04,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "curriculum learning for natural language understanding\n",
      "visualizing and understanding curriculum learning for long short-term memory networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 126/571 [07:09<25:26,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "distilling annotations via active imitation learning\n",
      "random expert distillation: imitation learning via expert policy support estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 145/571 [08:19<28:42,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "ecpe-2d: emotion-cause pair extraction based on joint two-dimensional representation, interaction and prediction\n",
      "emotion-cause pair extraction: a new task to emotion analysis in texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 147/571 [08:27<28:34,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "effective inter-clause modeling for end-to-end emotion-cause pair extraction\n",
      "end-to-end emotion-cause pair extraction via learning to link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 176/571 [10:11<29:52,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "explicit semantic decomposition for definition generation\n",
      "semantic composition and decomposition: from recognition to generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 218/571 [12:39<22:46,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "graph neural news recommendation with unsupervised preference disentanglement\n",
      "graph neural news recommendation with long-term and short-term interest modeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 251/571 [14:28<17:45,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving disentangled text representation learning with information-theoretic guidance\n",
      "improving disentangled representation learning with the beta bernoulli process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 255/571 [14:41<16:56,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving image captioning with better use of caption\n",
      "hidden state guidance: improving image captioning using an image conditioned autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 258/571 [14:50<16:51,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving multimodal named entity recognition via entity span detection with unified multimodal transformer\n",
      "a multimodal deep learning approach for named entity recognition from social media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 264/571 [15:11<18:12,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "in neural machine translation, what does transfer learning transfer?\n",
      "exploring benefits of transfer learning in neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 270/571 [15:36<19:57,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "inset: sentence infilling with inter-sentential transformer\n",
      "inset: sentence infilling with inter-sentential generative pre-training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 308/571 [17:44<14:49,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning to ask more: semi-autoregressive sequential question generation under dual-graph interaction\n",
      "semi-autoregressive neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 333/571 [19:18<14:07,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "meta-reinforced multi-domain state generator for dialogue systems\n",
      "transferable multi-domain state generator for task-oriented dialogue systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 354/571 [20:28<12:24,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multi-hypothesis machine translation evaluation\n",
      "pairwise neural machine translation evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 360/571 [20:48<12:22,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multi-source meta transfer for low resource multiple-choice question answering\n",
      "improving question answering with external knowledge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 407/571 [23:38<08:57,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "predicting the topical stance and political leaning of media using tweets\n",
      "predicting the topical stance of media and popular twitter users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 409/571 [23:46<09:25,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "premise selection in natural language mathematical texts\n",
      "natural language premise selection: finding supporting statements for mathematical text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 434/571 [25:15<07:36,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "reinceptione: relation-aware inception network with joint local-global structural information for knowledge graph embedding\n",
      "relation-aware entity alignment for heterogeneous knowledge graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 437/571 [25:27<08:33,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "relation-aware collaborative learning for unified aspect-based sentiment analysis\n",
      "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 480/571 [28:03<05:56,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "spanmlt: a span-based multi-task learning framework for pair-wise aspect and opinion terms extraction\n",
      "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 492/571 [28:47<04:43,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "structural information preserving for graph-to-text generation\n",
      "structural neural encoders for amr-to-text generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 569/571 [33:24<00:07,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "zero-shot text classification via reinforced self-training\n",
      "integrating semantic knowledge to tackle zero-shot text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 571/571 [33:30<00:00,  3.52s/it]\n",
      " 13%|█▎        | 28/208 [01:27<09:33,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "camouflaged chinese spam content detection with semi-supervised generative active learning\n",
      "gans for semi-supervised opinion spam detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/208 [01:56<09:36,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "content word aware neural machine translation\n",
      "selective attention for context-aware neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 99/208 [05:31<06:03,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "language-aware interlingua for multilingual neural machine translation\n",
      "a neural interlingua for multilingual machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 102/208 [05:43<06:33,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning low-resource end-to-end goal-oriented dialog for fast and reliable system deployment\n",
      "learning end-to-end goal-oriented dialog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 121/208 [06:51<05:47,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multimodal and multiresolution speech recognition with transformers\n",
      "multiresolution and multimodal speech recognition with transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 126/208 [07:07<04:55,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "neural graph matching networks for chinese short text matching\n",
      "graph matching networks for learning the similarity of graph structured objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 189/208 [10:45<01:08,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "tree-structured neural topic model\n",
      "structured neural topic models for reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 207/208 [11:47<00:03,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "``you sound just like your father’’ commercial machine translation systems include stylistic biases\n",
      "reducing gender bias in neural machine translation as a domain adaptation problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 208/208 [11:49<00:00,  3.41s/it]\n",
      "100%|██████████| 43/43 [02:22<00:00,  3.32s/it]\n",
      "  4%|▍         | 2/49 [00:06<02:13,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "a geometry-inspired attack for generating natural language adversarial examples\n",
      "a geometry-inspired decision-based attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 24/49 [01:11<01:20,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "υbleu: uncertainty-aware automatic evaluation method for open-domain dialogue systems\n",
      "better automatic evaluation of open-domain dialogue systems with contextualized embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49/49 [02:28<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"papers_with_arxiv_link.md\", \"w\") as f:\n",
    "    f.write(\"### Long Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, long_papers)\n",
    "    f.write(\"### Short Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, short_papers)\n",
    "    f.write(\"### System Demonstrations\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, demo_papers)\n",
    "    f.write(\"### Student Research Workshop\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link(f, student_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aw4p7l8eCYX2"
   },
   "source": [
    "# Sorting by Topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hunkim/ACL-2020-Papers/blob/master/generate_paper_list_with_arxiv_link.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c36Fa3LPCovq",
    "outputId": "334213e3-e0f7-4cb8-f751-768d887f73eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/joohong/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zqDjrwyoHEPu"
   },
   "outputs": [],
   "source": [
    "#FIXME: Better way to get human readable topic names from LDA topics?\n",
    "def list2topiclist(list, num_topics = 8):\n",
    "    processed_docs = []\n",
    "    for line in list:\n",
    "        processed_line = preprocess(line[0])\n",
    "        processed_docs.append(processed_line)\n",
    "\n",
    "        dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "  \n",
    "    lda = gensim.models.LdaModel(bow_corpus, num_topics, \n",
    "                                 id2word = dictionary, passes = 10)\n",
    "\n",
    "\n",
    "    def get_topic_title(idx, topn=3):\n",
    "        topn_terms = [dictionary[x[0]] for x in lda.get_topic_terms(idx, topn)]\n",
    "        return \" \".join(topn_terms)\n",
    "\n",
    "    # Create topic title\n",
    "    list_topic_titles = []\n",
    "    for i in range(num_topics):\n",
    "        list_topic_titles.append(get_topic_title(i))\n",
    "\n",
    "    # Assign list to topic\n",
    "    topic_dict = {}\n",
    "    for line in list:\n",
    "        processed_line = preprocess(line[0])\n",
    "        bow_vector = dictionary.doc2bow(processed_line)\n",
    "        line_topic = sorted(lda.get_document_topics(bow_vector), \n",
    "                            key=lambda tup: tup[1], reverse=True)\n",
    "        topic_title = list_topic_titles[line_topic[0][0]]\n",
    "\n",
    "        if topic_title not in topic_dict:\n",
    "            topic_dict[topic_title] = []\n",
    "\n",
    "        topic_dict[topic_title].append(line)\n",
    "  \n",
    "    return topic_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "zw8jDBlNNGYH",
    "outputId": "8bdee55b-ee6d-46b9-d98f-a2384065dd38",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task tool interact\n",
      "clinic search question\n",
      "languag natur toolkit\n",
      "evalu multilingu sourc\n",
      "generat evid discoveri\n",
      "time real evid\n",
      "toolkit deep label\n",
      "news knowledg analysi\n"
     ]
    }
   ],
   "source": [
    "topics = list2topiclist(demo_papers)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "796iR6xmLnMd"
   },
   "outputs": [],
   "source": [
    "def generate_paper_list_with_arxiv_link_topic(f, papers):\n",
    "    topic_papers = list2topiclist(papers)\n",
    "    for topic in topic_papers:\n",
    "        f.write(f\"#### {topic}\\n\\n\")\n",
    "        generate_paper_list_with_arxiv_link(f, topic_papers[topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "11VvQQBRMZjY",
    "outputId": "a2c99d6e-5237-46e8-a6dd-72f012af6553",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/110 [00:10<06:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "a generative model for joint natural language understanding and generation\n",
      "semi-supervised neural text generation by joint learning of natural language generation and natural language understanding models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 28/110 [01:39<05:22,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "ecpe-2d: emotion-cause pair extraction based on joint two-dimensional representation, interaction and prediction\n",
      "emotion-cause pair extraction: a new task to emotion analysis in texts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 87/110 [05:09<01:24,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "relation-aware collaborative learning for unified aspect-based sentiment analysis\n",
      "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 93/110 [05:29<00:57,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "spanmlt: a span-based multi-task learning framework for pair-wise aspect and opinion terms extraction\n",
      "an interactive multi-task learning network for end-to-end aspect-based sentiment analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [06:34<00:00,  3.58s/it]\n",
      " 12%|█▏        | 10/86 [00:33<03:50,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "attentive pooling with learnable norms for text representation\n",
      "attentive pooling networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 15/86 [00:52<04:21,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "curriculum learning for natural language understanding\n",
      "visualizing and understanding curriculum learning for long short-term memory networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 17/86 [00:59<04:01,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "distilling annotations via active imitation learning\n",
      "random expert distillation: imitation learning via expert policy support estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 28/86 [01:38<03:36,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "explicit semantic decomposition for definition generation\n",
      "semantic composition and decomposition: from recognition to generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 38/86 [02:15<03:04,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "graph neural news recommendation with unsupervised preference disentanglement\n",
      "graph neural news recommendation with long-term and short-term interest modeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 50/86 [02:57<01:57,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning to ask more: semi-autoregressive sequential question generation under dual-graph interaction\n",
      "semi-autoregressive neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 73/86 [04:16<00:44,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "structural information preserving for graph-to-text generation\n",
      "structural neural encoders for amr-to-text generation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [05:04<00:00,  3.55s/it]\n",
      " 53%|█████▎    | 23/43 [01:18<00:57,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving multimodal named entity recognition via entity span detection with unified multimodal transformer\n",
      "a multimodal deep learning approach for named entity recognition from social media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 25/43 [01:26<01:03,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "inset: sentence infilling with inter-sentential transformer\n",
      "inset: sentence infilling with inter-sentential generative pre-training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [02:23<00:00,  3.34s/it]\n",
      " 11%|█         | 10/89 [00:32<04:45,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "adaptive compression of word embeddings\n",
      "online embedding compression for text classification using low rank matrix factorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 13/89 [00:41<04:11,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "bilingual dictionary based neural machine translation without using parallel sentences\n",
      "bridging neural machine translation and bilingual dictionaries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 59/89 [03:24<01:56,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "reinceptione: relation-aware inception network with joint local-global structural information for knowledge graph embedding\n",
      "relation-aware entity alignment for heterogeneous knowledge graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [05:05<00:00,  3.44s/it]\n",
      " 25%|██▍       | 17/69 [00:58<03:05,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "contextualized weak supervision for text classification\n",
      "weakly-supervised neural text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 55/69 [03:12<00:52,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "predicting the topical stance and political leaning of media using tweets\n",
      "predicting the topical stance of media and popular twitter users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [04:05<00:00,  3.56s/it]\n",
      " 28%|██▊       | 13/47 [00:44<02:00,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "effective inter-clause modeling for end-to-end emotion-cause pair extraction\n",
      "end-to-end emotion-cause pair extraction via learning to link\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [02:43<00:00,  3.47s/it]\n",
      " 73%|███████▎  | 24/33 [01:18<00:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "premise selection in natural language mathematical texts\n",
      "natural language premise selection: finding supporting statements for mathematical text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:51<00:00,  3.39s/it]\n",
      "  3%|▎         | 3/94 [00:11<06:04,  4.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "addressing posterior collapse with mutual information for improved variational neural machine translation\n",
      "improved variational neural machine translation by promoting mutual information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 12/94 [00:46<05:08,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "boosting neural machine translation with similar translations\n",
      "neural machine translation from simplified translations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 14/94 [00:54<05:15,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "cross-lingual unsupervised sentiment classification with multi-view transfer learning\n",
      "multi-source cross-lingual model transfer: learning what to share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 32/94 [02:02<03:54,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving disentangled text representation learning with information-theoretic guidance\n",
      "improving disentangled representation learning with the beta bernoulli process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 34/94 [02:16<05:09,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "improving image captioning with better use of caption\n",
      "hidden state guidance: improving image captioning using an image conditioned autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 37/94 [02:26<03:39,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "in neural machine translation, what does transfer learning transfer?\n",
      "exploring benefits of transfer learning in neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 48/94 [03:03<02:26,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "meta-reinforced multi-domain state generator for dialogue systems\n",
      "transferable multi-domain state generator for task-oriented dialogue systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 50/94 [03:12<02:42,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multi-hypothesis machine translation evaluation\n",
      "pairwise neural machine translation evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 53/94 [03:23<02:34,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multi-source meta transfer for low resource multiple-choice question answering\n",
      "improving question answering with external knowledge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 93/94 [05:45<00:03,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "zero-shot text classification via reinforced self-training\n",
      "integrating semantic knowledge to tackle zero-shot text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [05:47<00:00,  3.70s/it]\n",
      "100%|██████████| 26/26 [01:22<00:00,  3.19s/it]\n",
      "100%|██████████| 23/23 [01:17<00:00,  3.37s/it]\n",
      "100%|██████████| 31/31 [01:44<00:00,  3.37s/it]\n",
      "100%|██████████| 8/8 [00:27<00:00,  3.38s/it]\n",
      "  0%|          | 0/31 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "tree-structured neural topic model\n",
      "structured neural topic models for reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 17/31 [01:02<00:51,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "learning low-resource end-to-end goal-oriented dialog for fast and reliable system deployment\n",
      "learning end-to-end goal-oriented dialog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [01:52<00:00,  3.64s/it]\n",
      " 51%|█████▏    | 20/39 [01:15<01:19,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "multimodal and multiresolution speech recognition with transformers\n",
      "multiresolution and multimodal speech recognition with transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 22/39 [01:23<01:07,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "neural graph matching networks for chinese short text matching\n",
      "graph matching networks for learning the similarity of graph structured objects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [02:26<00:00,  3.77s/it]\n",
      " 14%|█▍        | 4/28 [00:13<01:21,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "camouflaged chinese spam content detection with semi-supervised generative active learning\n",
      "gans for semi-supervised opinion spam detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 13/28 [00:47<00:54,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "interpretable operational risk classification with semi-supervised variational autoencoder\n",
      "disentangled variational auto-encoder for semi-supervised learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 14/28 [00:51<00:52,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "language-aware interlingua for multilingual neural machine translation\n",
      "a neural interlingua for multilingual machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:39<00:00,  3.55s/it]\n",
      " 14%|█▎        | 3/22 [00:10<01:08,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "content word aware neural machine translation\n",
      "selective attention for context-aware neural machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [01:18<00:00,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "``you sound just like your father’’ commercial machine translation systems include stylistic biases\n",
      "reducing gender bias in neural machine translation as a domain adaptation problem\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:23<00:00,  3.30s/it]\n",
      "100%|██████████| 7/7 [00:22<00:00,  3.24s/it]\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.45s/it]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.74s/it]\n",
      "100%|██████████| 5/5 [00:18<00:00,  3.68s/it]\n",
      "100%|██████████| 6/6 [00:21<00:00,  3.62s/it]\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.61s/it]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.92s/it]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.95s/it]\n",
      " 11%|█         | 1/9 [00:04<00:33,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "a geometry-inspired attack for generating natural language adversarial examples\n",
      "a geometry-inspired decision-based attack\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:29<00:00,  3.25s/it]\n",
      "100%|██████████| 8/8 [00:19<00:00,  2.48s/it]\n",
      " 46%|████▌     | 6/13 [00:17<00:21,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT MATCHED\n",
      "υbleu: uncertainty-aware automatic evaluation method for open-domain dialogue systems\n",
      "better automatic evaluation of open-domain dialogue systems with contextualized embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:40<00:00,  3.13s/it]\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.46s/it]\n",
      "100%|██████████| 6/6 [00:22<00:00,  3.70s/it]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.72s/it]\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.54s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"papers_with_arxiv_link_topic.md\", \"w\") as f:\n",
    "    f.write(\"### Long Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link_topic(f, long_papers)\n",
    "    f.write(\"### Short Papers\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link_topic(f, short_papers)\n",
    "    f.write(\"### System Demonstrations\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link_topic(f, demo_papers)\n",
    "    f.write(\"### Student Research Workshop\\n\\n\")\n",
    "    generate_paper_list_with_arxiv_link_topic(f, student_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKaDBI55CNRK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "generate_paper_list_with_arxiv_link.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env/python",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
