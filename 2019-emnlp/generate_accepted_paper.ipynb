{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open('data/oral_paper_by_topic.json') as json_file:\n",
    "    oral_papers = json.load(json_file)\n",
    "with open('data/poster_demo_paper_by_topic.json') as json_file:\n",
    "    poster_demo_papers = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Machine Learning': ['Attending to Future Tokens for Bidirectional Sequence Generation (#1443)',\n",
       "  'Attention is Not Not Explanation (#526)',\n",
       "  'Practical Obstacles to Deploying Active Learning (#1176)',\n",
       "  'Transfer Learning Between Related Tasks Using Expected Label Proportions (#1207)',\n",
       "  'Insertion-based Decoding with automatically Inferred Generation Order (#TACL-1732)',\n",
       "  'Are We Modeling the Task or the Annotator? An Investigation of Annotator Bias in Natural Language Understanding Datasets (#1092)',\n",
       "  'Robust Text Classifier on Test-Time Budgets (#1128)',\n",
       "  'Commonsense Knowledge Mining from Pretrained Models (#3289)',\n",
       "  'RNN Architecture Learning with Sparse Regularization (#3428)',\n",
       "  'Universal Trigger Sequences for Attacking and Analyzing NLP (#1515)',\n",
       "  'To Annotate or Not? Unsupervised Prediction of Performance Drop due to Domain Shift (#2756)',\n",
       "  'Adaptively Sparse Transformers (#2900)',\n",
       "  'Show Your Work: Improved Reporting of Experimental Results (#3277)',\n",
       "  'A Deep Factorization of Style and Structure in Fonts (#3999)'],\n",
       " 'Lexical Semantics': ['Knowledge Enhanced Contextual Word Representations (#3403)',\n",
       "  'How Contextual are Contextualized Word Representations? (#208)',\n",
       "  'Room to Glo: A Systematic Comparison of Semantic Change Detection Approaches with Word Embeddings (#783)',\n",
       "  'On Correlations between Word Vector Sets (#3976)',\n",
       "  'Game Theory Meets Embeddings: a Unified Framework for Word Sense Disambiguation (#1724)',\n",
       "  'Cross-lingual Semantic Specialization via Lexical Relation Induction (#1735)',\n",
       "  'Modelling the interplay of metaphor and emotion through multitask learning (#2670)',\n",
       "  'How well do NLI models capture verb veridicality? (#3460)',\n",
       "  'Modeling Color Terminology Across Thousands of Languages (#3515)',\n",
       "  'Negative Focus Detection via Contextual Attention Mechanisms (#1314)',\n",
       "  'Exploring Human Gender Stereotypes with Word Association Test (#1912)',\n",
       "  'Still a Pain in the Neck: Evaluating Text Representations on Lexical Composition (#TACL-1729)',\n",
       "  \"Where''s My Head? Definition, Dataset and Models for Numeric Fused-Heads Identification and Resolution (#TACL-1648)\"],\n",
       " 'Dialog and Interactive Systems': ['Guided Dialog Policy Learning: Reward Estimation for Multi-Domain Task-Oriented Dialog (#166)',\n",
       "  'Multi-hop Selector Network for Multi-turn Response Selection in Retrieval-based Chatbots (#554)',\n",
       "  'MoEL: Mixture of Empathetic Listeners (#1053)',\n",
       "  'Entity-Consistent End-to-end Task-Oriented Dialogue System with KB Retriever (#2430)',\n",
       "  'Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation (#3756)',\n",
       "  'TaskMaster Dialog Corpus: Toward a Realistic and Diverse Dataset (#510)',\n",
       "  'MultiDoGO: Multi-Domain Goal-Oriented Dialogues (#1564)',\n",
       "  'Build it Break it Fix it for Dialogue Safety: Robustness from Adversarial Human Attack (#1186)',\n",
       "  'GECOR: An End-to-End Generative Ellipsis and Co-reference Resolution Model for Task-Oriented Dialogue (#1853)',\n",
       "  'Task-Oriented Conversation Generation Using Heterogeneous Memory Networks (#496)'],\n",
       " 'Sentiment Analysis and Argument Mining': ['DialogueGCN: A Graph-based Network for Emotion Recognition in Conversation (#2092)',\n",
       "  'Knowledge-Enriched Transformer for Emotion Detection in Textual Conversations (#1814)',\n",
       "  'Interpretable Relevant Emotion Ranking with Event-Driven Attention (#3544)',\n",
       "  'Justifying Recommendations using Distantly-Labeled Reviews and Fined-Grained Aspects (#518)',\n",
       "  'Using Customer Service Dialogues for Satisfaction Analysis with Context-Assisted Multiple Instance Learning (#204)',\n",
       "  'What Gets Echoed? Understanding the “Pointers” in Explanations of Persuasive Arguments (#2089)',\n",
       "  'Modeling Frames in Argumentation (#2267)',\n",
       "  'AMPERSAND: Argument Mining for PERSuAsive oNline Discussions (#3321)',\n",
       "  'Evaluating adversarial attacks against multiple fact verification systems (#427)',\n",
       "  'Nonsense!: Quality Control via Two-Step Reason Selection for Annotating Local Acceptability and Related Attributes in News Editorials (#564)',\n",
       "  'On the Importance of Delexicalization for Fact Verification (#2984)',\n",
       "  'Towards Debiasing Fact Verification Models (#3338)',\n",
       "  'Recognizing Conflict Opinions in Aspect-level Sentiment Classification with Dual Attention Networks (#911)',\n",
       "  'Investigating Dynamic Routing in Tree-Structured LSTM for Sentiment Analysis (#1395)',\n",
       "  'Aspect-based Sentiment Classification with Aspect-specific Graph Convolutional Networks (#381)',\n",
       "  'Coupling Global and Local Context for Unsupervised Aspect Extraction (#1988)',\n",
       "  'Transferable End-to-End Aspect-based Sentiment Analysis with Selective Adversarial Learning (#65)',\n",
       "  'CAN: Constrained Attention Networks for Multi-Aspect Sentiment Analysis (#1995)',\n",
       "  'Leveraging Just a Few Keywords for Fine-Grained Aspect Detection Through Weakly Supervised Co-Training (#3207)'],\n",
       " 'Summarization and Generation': ['Neural Text Summarization: A Critical Evaluation (#3687)',\n",
       "  'Neural data-to-text generation: A comparison between pipeline and end-to-end architectures (#2586)',\n",
       "  'MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance (#1175)',\n",
       "  'Select and Attend: Towards Controllable Content Selection in Text Generation (#3049)',\n",
       "  'Sentence-Level Content Planning and Style Specification for Neural Text Generation (#3357)'],\n",
       " 'Sentence-level Semantics': ['Translate and Label! An Encoder-Decoder Approach for Cross-lingual Semantic Role Labeling (#2740)',\n",
       "  'Syntax-Enhanced Self-Attention-Based Semantic Role Labeling (#2106)',\n",
       "  'VerbAtlas: a Novel Large-Scale Verbal Semantic Resource and Its Application to Semantic Role Labeling (#2213)',\n",
       "  'Parameter-free Sentence Embedding via Orthogonal Basis (#1099)',\n",
       "  'Evaluation Benchmarks and Learning Criteria for Discourse-Aware Sentence Representations (#3807)',\n",
       "  'Learning Semantic Parsers from Denotations with Latent Structured Alignments and Abstract Programs (#2676)',\n",
       "  'Broad-Coverage Semantic Parsing as Transduction (#263)',\n",
       "  'Core Semantic First: A Top-down Approach for AMR Parsing (#1544)',\n",
       "  \"Don't paraphrase, detect! Rapid and Effective Data Collection for Semantic Parsing (#2904)\",\n",
       "  'Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond (#TACL-1742)'],\n",
       " 'Speech, Vision, Robotics, Multimodal and Grounding': ['Extracting Possessions from Social Media: Images Complement Language (#3013)',\n",
       "  'Learning to Speak and Act in a Fantasy Text Adventure Game (#1243)',\n",
       "  'Help, Anna! Vision-based Navigation with Natural Multimodal Assistance via Retrospective Curiosity-Encouraging Imitation Learning (#1542)',\n",
       "  'Incorporating Visual Semantics into Sentence Representations within a Grounded Space (#2247)',\n",
       "  'Neural Naturalist: Generating Fine-Grained Image Comparisons (#3024)',\n",
       "  'LXMERT: Learning Cross-Modality Encoder Representations from Transformers (#3048)',\n",
       "  'Phrase Grounding by Soft-Label Chain Conditional Random Field (#3765)',\n",
       "  'What You See is What You Get: Visual Pronoun Coreference Resolution in Conversations (#549)',\n",
       "  'YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension (#122)',\n",
       "  'DEBUG: A Dense Bottom-Up Grounding Approach for Natural Language Video Localization (#167)'],\n",
       " 'Information Extraction': ['Fine-Grained Evaluation for Entity Linking (#116)',\n",
       "  'Supervising Unsupervised Open Information Extraction Models (#3069)',\n",
       "  'Neural Cross-Lingual Event Detection with Minimal Parallel Resources (#1723)',\n",
       "  'KnowledgeNet: A Benchmark Dataset for Knowledge Base Population (#1258)',\n",
       "  'Effective Use of Transformer Networks for Entity Tracking (#3308)',\n",
       "  'Improving Distantly-Supervised Relation Extraction with Joint Label Embedding (#337)',\n",
       "  'Leverage Lexical Knowledge for Chinese Named Entity Recognition via Collaborative Graph Network (#566)',\n",
       "  'Looking Beyond Label Noise: Shifted Label Distribution Matters in Distantly Supervised Relation Extraction (#1057)',\n",
       "  'Easy First Relation Extraction with Information Redundancy (#1640)',\n",
       "  'Dependency-Guided LSTM-CRF for Named Entity Recognition (#2509)',\n",
       "  'CrossWeigh: Training Named Entity Tagger from Imperfect Annotations (#2712)',\n",
       "  'A Little Annotation does a Lot of Good: A Study in Bootstrapping Low-resource Named Entity Recognizers (#3259)',\n",
       "  'Open Domain Web Keyphrase Extraction Beyond Language Modeling (#1119)',\n",
       "  'TuckER: Tensor Factorization for Knowledge Graph Completion (#990)',\n",
       "  'Weakly Supervised Domain Detection (#TACL-1712)',\n",
       "  'Event Detection with Multi-Order Graph Convolution and Aggregated Attention (#835)',\n",
       "  'Coverage of Information Extraction from Sentences and Paragraphs (#1285)',\n",
       "  'HMEAE: Hierarchical Modular Event Argument Extraction (#2354)',\n",
       "  'Entity, Relation, and Event Extraction with Contextualized Span Representations (#3930)'],\n",
       " 'Semantics': ['Analytical Methods for Interpretable Ultradense Word Embeddings (#75)',\n",
       "  'Investigating Meta-Learning Algorithms for Low-Resource Natural Language Understanding Tasks (#3142)',\n",
       "  'Retrofitting Contextualized Word Embeddings with Paraphrases (#3045)',\n",
       "  'Incorporating Contextual and Syntactic Structures Improves Semantic Similarity Modeling (#3508)'],\n",
       " 'Discourse, Summarization, and Generation': ['Neural Linguistic Steganography (#3399)',\n",
       "  'The Feasibility of Embedding Based Automatic Evaluation for Single Document Summarization (#3018)',\n",
       "  'Attention Optimization for Abstractive Document Summarization (#1918)',\n",
       "  'Rewarding Coreference Resolvers for Being Consistent with World Knowledge (#2020)'],\n",
       " 'Text Mining and NLP Applications': ['An Empirical Study of Incorporating Pseudo Data into Grammatical Error Correction (#740)',\n",
       "  'A Multilingual Topic Model for Learning Weighted Topic Links Across Incomparable Corpora (#1257)',\n",
       "  'Measure Country-Level Socio-Economic Indicators with Streaming News: An Empirical Study (#3730)',\n",
       "  'Towards Extracting Medical Family History from Natural Language Interactions: A New Dataset and Baselines (#2903)',\n",
       "  '(Male, Bachelor) and (Female, Ph.D) have different connotations: Parallelly Annotated Stylistic Language Dataset with Multiple Personas (#3793)',\n",
       "  'Movie Plot Analysis via Turning Point Identification (#244)',\n",
       "  'Latent Suicide Risk Detection on Microblog via Suicide-Oriented Word Embeddings and Layered Attention (#2488)',\n",
       "  'Deep Ordinal Regression for Pledge Specificity Prediction (#1903)',\n",
       "  'Enabling Robust Grammatical Error Correction in New Domains: Datasets, Metrics, and Analyses (#TACL-1677)',\n",
       "  'The Myth of Blind Review Revisited: Experiments on ACL vs. EMNLP (#2233)',\n",
       "  'Uncover Sexual Harassment Patterns from Personal Stories by Joint Key Element Extraction and Categorization (#2653)',\n",
       "  'Identifying Predictive Causal Factors from News Streams (#2864)',\n",
       "  'Training Data Augmentation for Detecting Adverse Drug Reactions in User-Generated Content (#3011)',\n",
       "  'Deep Reinforcement Learning-based Text Anonymization against Private-Attribute Inference (#3160)'],\n",
       " 'Neural Machine Translation': ['Enhancing Context Modeling with a Query-Guided Capsule Network for Document-level NMT (#2416)',\n",
       "  'Simple, Scalable Adaptation for Neural Machine Translation (#3252)',\n",
       "  'Controlling Text Complexity in Neural Machine Translation (#3177)',\n",
       "  'Investigating Multilingual NMT Representations at Scale (#1388)',\n",
       "  'Hierarchical Modeling of Global Context for Document-Level Neural Machine Translation (#1423)'],\n",
       " 'Question Answering': ['Cross-Lingual Machine Reading Comprehension (#8)',\n",
       "  'A Multi-Type Multi-Span Network for Reading Comprehension that Requires Discrete Reasoning (#582)',\n",
       "  'Neural Duplicate Question Detection without Labeled Training Data (#880)',\n",
       "  'Asking Clarification Questions in Knowledge-Based Question Answering (#889)',\n",
       "  'Multi-View Domain Adapted Sentence Embeddings for Low-Resource Unsupervised Duplicate Question Detection (#1646)',\n",
       "  'Interactive Language Learning by Question Answering (#1367)',\n",
       "  \"What's Missing: A Knowledge Gap Guided Approach for Multi-hop Question Answering (#3238)\",\n",
       "  'KagNet: Learning to Answer Commonsense Questions with Knowledge-Aware Graph Networks (#436)',\n",
       "  'Learning with Limited Data for Multilingual Reading Comprehension (#3518)',\n",
       "  'A Discrete Hard EM Approach for Weakly Supervised Question Answering (#3778)'],\n",
       " 'Social Media and Computational Social Science': ['Multi-label Categorization of Accounts of Sexism using a Neural Framework (#172)',\n",
       "  \"The Trumpiest Trump? Identifying a Subject's Most Characteristic Tweets (#1462)\",\n",
       "  'Finding Microaggressions in the Wild: A Case for Locating Elusive Phenomena in Social Media Posts (#2950)',\n",
       "  'Reinforced Product Metadata Selection for Helpfulness Assessment of Customer Reviews (#694)',\n",
       "  'Learning Invariant Representations of Social Media Users (#3557)'],\n",
       " 'Discourse and Pragmatics': ['A Unified Neural Coherence Model (#1792)',\n",
       "  'Topic-Guided Coherence Modeling for Sentence Ordering by Preserving Global and Local Information (#2642)',\n",
       "  'Neural Generative Rhetorical Structure Parsing (#4060)',\n",
       "  'Weak Supervision for Learning Discourse Structure (#2453)',\n",
       "  'Predicting Discourse Structure using Distant Supervision from Sentiment (#2625)'],\n",
       " 'Tagging, Chunking, Syntax and Parsing': ['Designing and Interpreting Probes with Control Tasks (#4063)',\n",
       "  'Specializing Word Embeddings (for Parsing) by Information Bottleneck (#1357)',\n",
       "  'Deep Contextualized Word Embeddings in Transition-Based and Graph-Based Dependency Parsing - A Tale of Two Parsers Revisited (#2799)',\n",
       "  'Semantic graph parsing with recurrent neural network DAG grammars (#2863)',\n",
       "  '75 Languages, 1 Model: Parsing Universal Dependencies Universally (#1221)'],\n",
       " 'Linguistic Theories, Cognitive Modeling and Psycholinguistics': ['Is the Red Square Big? MALeViC: Modeling Adjectives Leveraging Visual Contexts (#2585)',\n",
       "  \"Investigating BERT's Knowledge of Language: Five Analysis Methods with NPIs (#3650)\",\n",
       "  'Representation of Constituents in Neural Language Models: - Coordination Phrase as a Case Study (#3929)',\n",
       "  'Towards Zero-shot Language Modelling (#1745)',\n",
       "  'Neural Network Acceptability Judgments (#TACL-1710)'],\n",
       " 'Machine Translation and Multilinguality': ['Lost in Evaluation: Misleading Benchmarks for Bilingual Dictionary Induction (#1131)',\n",
       "  'Towards Realistic Practices In Low-Resource Natural Language Processing: The Development Set (#1266)',\n",
       "  'Synchronously Generating Two Languages with Interactive Decoding (#1478)',\n",
       "  'On NMT Search Errors and Model Errors: Cat Got Your Tongue? (#1868)',\n",
       "  'Do We Really Need Fully Unsupervised Cross-Lingual Embeddings? (#2459)',\n",
       "  'Weakly-Supervised Concept-based Adversarial Learning for Cross-lingual Word Embeddings (#2491)',\n",
       "  'Aligning Cross-lingual Entities with Multi-Aspect Information (#3541)',\n",
       "  'Contrastive Language Adaptation for Cross-Lingual Stance Detection (#2498)',\n",
       "  'Jointly Learning to Align and Translate with Transformer Models (#422)',\n",
       "  'Understanding Data Augmentation in Neural Machine Translation: Two Perspectives towards Generalization (#2192)',\n",
       "  'Simple and Effective Noisy Channel Modeling for Neural Machine Translation (#2869)',\n",
       "  'MultiFiT: Efficient Multi-lingual Language Model Fine-tuning (#745)',\n",
       "  'Hint-based Training for Non-AutoRegressive Machine Translation (#1064)',\n",
       "  'Two New Evaluation Datasets for Low-Resource Machine Translation: Nepali-English and Sinhala English (#3349)',\n",
       "  'Constant-Time Machine Translation with Conditional Masked Language Models (#1204)',\n",
       "  'Learning to Copy for Automatic Post-Editing (#777)'],\n",
       " 'Reasoning and Question Answering': ['Going on a vacation takes longer than “Going for a walk”: A Study of Temporal Commonsense Understanding (#2533)',\n",
       "  'QAInfomax: Learning Robust Question Answering System by Mutual Information Maximization (#2798)',\n",
       "  'Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations (#329)',\n",
       "  'How Reasonable are Common-Sense Reasoning Tasks: A Case-Study on the Winograd Schema Challenge and SWAG (#586)'],\n",
       " 'Generation': ['Pun-GAN: Generative Adversarial Network for Pun Generation (#267)',\n",
       "  'Multi-Task Learning with Language Modeling for Question Generation (#3820)',\n",
       "  'Autoregressive Text Generation beyond Feedback Loops (#3506)',\n",
       "  'The Woman Worked as a Babysitter: On Biases in Language Generation (#3874)',\n",
       "  'Counterfactual Story Reasoning and Generation (#3328)',\n",
       "  'Encode, Tag, Realize: High-Precision Text Editing (#2395)',\n",
       "  'Answer-guided and Semantic Coherent Question Generation in Open-domain Conversation (#128)',\n",
       "  'Read, Attend and Comment: A Deep Architecture for Automatic News Comment Generation (#1947)',\n",
       "  'A Topic Augmented Text Generation Model: Joint Learning of Semantics and Structural Features (#2822)',\n",
       "  'A Modular Architecture for Unsupervised Sarcasm Generation (#2725)',\n",
       "  'Interpoetry: Generating Classical Chinese Poems from Vernacular Chinese (#2534)',\n",
       "  'Set to Ordered Text: Generating Discharge Instructions from Medical Billing Codes (#724)'],\n",
       " 'Summarization': ['Summary Cloze: A New Task for Content Selection in Topic-Focused Summarization (#1178)',\n",
       "  'Text Summarization with Pretrained Encoders (#392)',\n",
       "  'How to Write Summaries with Patterns? Learning towards Abstractive Summarization through Prototype Editing (#609)',\n",
       "  'Unsupervised Sentence Summarization using the Information Bottleneck Principle (#3219)',\n",
       "  'Improving Latent Alignment in Text Summarization by Generalizing the Pointer Generator (#3043)'],\n",
       " 'Information Retrieval and Document Analysis': ['Cross-Cultural Transfer Learning for Text Classification (#1036)',\n",
       "  'Combining Unsupervised Pre-training and Annotator Rationales to Improve Low-shot Text Classification (#1190)',\n",
       "  'Projection Sequence Networks for On-Device Text Classification (#3202)',\n",
       "  'Induction Networks for Few-Shot Text Classification (#3562)',\n",
       "  'Benchmarking Zero-shot Text Classification: Datasets, Evaluation and Entailment Approach (#2899)',\n",
       "  'Human-grounded Evaluations of Explanation Methods for Text Classification (#425)',\n",
       "  'A Context-based Framework for Modeling the Role and Function of On-line Resource Citations in Scientific Literature (#793)',\n",
       "  'Adversarial Reprogramming of Text Classification Neural Networks (#28)',\n",
       "  'Document Hashing with Mixture-Prior Generative Models (#1676)',\n",
       "  'Efficient Vector Retrieval under Maximum Inner Product (#3421)'],\n",
       " 'Reasoning': ['Social IQa: Commonsense Reasoning about Social Interactions (#1334)',\n",
       "  'Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning (#2866)',\n",
       "  'Posing Fair Generalization Tasks for Natural Language Inference (#1413)',\n",
       "  'Everything Happens for a Reason: Discovering the Purpose of Actions in Procedural Text (#3279)',\n",
       "  'CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text (#3183)'],\n",
       " 'Syntax, Parsing, and Linguistic Theories': ['Working Hard or Hardly Working: Challenges of Integrating Typology into Neural Dependency Parsers (#3860)',\n",
       "  'Cross-Lingual BERT Transformation for Zero-Shot Dependency Parsing (#1832)',\n",
       "  'Multilingual Grammar Induction with Continuous Language Identification (#3883)',\n",
       "  'Quantifying the Semantic Core of Gender Systems (#2637)'],\n",
       " 'Sentiment and Social Media': ['Perturbation Sensitivity Analysis for Detecting Unintended Model Biases (#3447)',\n",
       "  'Automatically Inferring Gender Associations from Language (#3519)',\n",
       "  'Reporting the Unreported: Event Extraction for Analyzing the Local Representation of Hate Crimes (#3715)',\n",
       "  'Minimally Supervised Learning of Affective Events Using Discourse Relations (#3493)'],\n",
       " 'Phonology, Word Segmentation, and Parsing': ['Constraint-based Learning of Phonological Processes (#451)',\n",
       "  'Detect Camouflaged Spam Content via StoneSkipping: Graph and Text Joint Embedding for Chinese Character Variation Representation (#1340)',\n",
       "  'A Generative Model for Punctuation in Dependency Trees (#TACL-1582)']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oral_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "\n",
    "def search_arxiv_link(title):\n",
    "    link = None\n",
    "    for j in search(title, tld=\"co.in\", num=10, stop=1, pause=0.5):\n",
    "        if 'arxiv.org/abs' in j:\n",
    "            thepage = urllib.request.urlopen(j)\n",
    "            soup = BeautifulSoup(thepage, \"html.parser\")\n",
    "            searched_title = ' '.join(soup.title.text.lower().split()[1:])\n",
    "            if similar(title, searched_title) > 0.8:\n",
    "                link = j\n",
    "                break\n",
    "            else:\n",
    "                print(\"ERROR\")\n",
    "                print(title)\n",
    "                print(searched_title)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/26 [00:57<24:05, 57.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "how contextual are contextualized word representations?\n",
      "how contextual are contextualized word representations? comparing the geometry of bert, elmo, and gpt-2 embeddings\n",
      "ERROR\n",
      "game theory meets embeddings: a unified framework for word sense disambiguation\n",
      "a game-theoretic approach to word sense disambiguation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 2/26 [01:49<22:25, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "multidogo: multi-domain goal-oriented dialogues\n",
      "transferable multi-domain state generator for task-oriented dialogue systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 3/26 [02:30<19:41, 51.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "evaluating adversarial attacks against multiple fact verification systems\n",
      "adversarial attacks against fact extraction and verification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 6/26 [04:58<15:51, 47.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "youmakeup: a large-scale domain-specific multimodal dataset for fine-grained semantic comprehension\n",
      "large scale fine-grained categorization and domain-specific transfer learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 7/26 [05:50<15:29, 48.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "fine-grained evaluation for entity linking\n",
      "fine-grained entity typing for domain independent entity linking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 12/26 [09:01<08:21, 35.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "kagnet: learning to answer commonsense questions with knowledge-aware graph networks\n",
      "kagnet: knowledge-aware graph networks for commonsense reasoning\n",
      "ERROR\n",
      "learning with limited data for multilingual reading comprehension\n",
      "multilingual extractive reading comprehension by runtime machine translation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 16/26 [10:56<04:48, 28.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "towards zero-shot language modelling\n",
      "improving zero-shot translation with language-independent constraints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 17/26 [11:19<04:04, 27.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "constant-time machine translation with conditional masked language models\n",
      "mask-predict: parallel decoding of conditional masked language models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 18/26 [12:36<05:37, 42.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "learning to copy for automatic post-editing\n",
      "a simple and effective approach to automatic post-editing with transfer learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [15:48<00:00, 20.27s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "self-attention enhanced cnns and collaborative curriculum learning for distantly supervised relation extraction\n",
      "improving distantly supervised relation extraction using word and entity based attention\n",
      "ERROR\n",
      "investigating capsule network and semantic feature on hyperplanes for text classification\n",
      "investigating capsule networks with dynamic routing for text classification\n",
      "ERROR\n",
      "label-specific document representation for multi-label text classification\n",
      "label-aware document representation via hybrid attention for extreme multi-label text classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 1/12 [02:17<25:13, 137.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "iterative dual domain adaptation for neural machine translation\n",
      "domain adaptation of neural machine translation by lexicon induction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 2/12 [05:33<25:50, 155.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "a progressive model to enable continual learning for semantic slot filling\n",
      "bert for joint intent classification and slot filling\n",
      "ERROR\n",
      "sampling matters! an empirical study of negative sampling strategies for learning of matching models in retrieval-based dialogue systems\n",
      "strategy of the negative sampling for training retrieval-based dialogue systems\n",
      "ERROR\n",
      "recurrent embedding for neural machine translation\n",
      "understanding neural machine translation by simplification: the case of encoder-free models\n",
      "ERROR\n",
      "low-resource neural machine translation by exploiting multilingualism through multi-step fine-tuning using n-way parallel corpora\n",
      "exploiting out-of-domain parallel data through multilingual transfer learning for low-resource neural machine translation\n",
      "ERROR\n",
      "improving visual dialog by learning to answer diverse questions\n",
      "improving generative visual dialog by answering diverse questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 3/12 [08:40<24:41, 164.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "span-based hierarchical semantic parsing for task-oriented dialog\n",
      "semantic parsing for task oriented dialog using hierarchical representations\n",
      "ERROR\n",
      "adaptive parameterization for neural dialogue generation\n",
      "domain adaptive dialog generation via meta learning\n",
      "ERROR\n",
      "modeling personalization in continuous space for response generation via augmented wasserstein autoencoders\n",
      "dialogwae: multimodal response generation with conditional wasserstein auto-encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [16:56<16:15, 162.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "bridging the defined and the defining: exploiting implicit lexical semantic relations in definition modeling\n",
      "definition modeling: learning to define word embeddings in natural language\n",
      "ERROR\n",
      "improved differentiable architecture search for language model and named entity recognition\n",
      "knowledge-augmented language model and its application to unsupervised named-entity recognition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 7/12 [20:04<14:11, 170.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "empirical study of transformer's attention mechanism via the lens of kernel\n",
      "transformer dissection: an unified understanding for transformer's attention via the lens of kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 8/12 [23:26<11:58, 179.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "neural news recommendation with heterogeneous user behavior\n",
      "neural news recommendation with attentive multi-view learning\n",
      "ERROR\n",
      "a neural citation count prediction model based on peer review text\n",
      "modeling and predicting citation count via recurrent neural network with long short-term memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 9/12 [26:02<08:38, 172.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "specificity-driven cascading approach for unsupervised sentiment modification\n",
      "learning sentiment memories for sentiment modification without parallel data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 10/12 [29:04<05:50, 175.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "revisiting the evaluation of theory of mind through question answering\n",
      "evaluating theory of mind in question answering\n",
      "ERROR\n",
      "clar: contextualized and lexicalized aspect representation for non-factoid question answering\n",
      "answer interaction in non-factoid question answering systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 11/12 [32:12<02:59, 179.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "cross-sentence n-ary relation extraction using lower-arity universal schemas\n",
      "cross-sentence n-ary relation extraction with graph lstms\n",
      "ERROR\n",
      "weakly supervised attention networks for entity extraction\n",
      "knowledge-guided pairwise reconstruction network for weakly supervised referring expression grounding\n",
      "ERROR\n",
      "a robust self-learning framework for cross-lingual text classification\n",
      "a robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings\n",
      "ERROR\n",
      "label embedding using hierarchical structure of labels for twitter classification\n",
      "hyperbolic interaction model for hierarchical multi-label classification\n",
      "ERROR\n",
      "neural news recommendation with multi-head self-attention\n",
      "neural news recommendation with attentive multi-view learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [35:21<00:00, 182.27s/it]\n"
     ]
    }
   ],
   "source": [
    "fo = open('accepted_papers.md', 'w')\n",
    "\n",
    "# Oral papers\n",
    "fo.write('### Oral Session\\n')\n",
    "for t in tqdm(oral_papers.keys()):\n",
    "    fo.write(f'#### {t}\\n')\n",
    "    for p in oral_papers[t]:\n",
    "        link = search_arxiv_link(' '.join(p.lower().split()[:-1]))\n",
    "        if link:\n",
    "            fo.write(f'- {p} [[arXiv]]({link})\\n')\n",
    "        else:\n",
    "            fo.write(f'- {p}\\n')\n",
    "    fo.write('\\n')\n",
    "\n",
    "# Poster & Demo papers\n",
    "fo.write('### Poster & Demo Session\\n')\n",
    "for t in tqdm(poster_demo_papers.keys()):\n",
    "    fo.write(f'#### {t}\\n')\n",
    "    for p in poster_demo_papers[t]:\n",
    "        link = search_arxiv_link(' '.join(p.lower().split()[:-1]))\n",
    "        if link:\n",
    "            fo.write(f'- {p} [[arXiv]]({link})\\n')\n",
    "        else:\n",
    "            fo.write(f'- {p}\\n')\n",
    "    fo.write('\\n')\n",
    "    \n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
